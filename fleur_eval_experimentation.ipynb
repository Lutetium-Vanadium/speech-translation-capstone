{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keith/miniconda3/envs/keith/lib/python3.11/site-packages/pyannote/audio/core/io.py:43: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(\"soundfile\")\n",
      "/home/keith/miniconda3/envs/keith/lib/python3.11/site-packages/pyannote/audio/pipelines/speaker_verification.py:43: UserWarning: torchaudio._backend.get_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  backend = torchaudio.get_audio_backend()\n",
      "INFO:speechbrain.utils.quirks:Applied quirks (see `speechbrain.utils.quirks`): [allow_tf32, disable_jit_profiling]\n",
      "INFO:speechbrain.utils.quirks:Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n",
      "/home/keith/miniconda3/envs/keith/lib/python3.11/site-packages/pyannote/audio/pipelines/speaker_verification.py:45: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0\n",
      "  from speechbrain.pretrained import (\n",
      "/home/keith/miniconda3/envs/keith/lib/python3.11/site-packages/pyannote/audio/pipelines/speaker_verification.py:53: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.\n",
      "  torchaudio.set_audio_backend(backend)\n",
      "/home/keith/miniconda3/envs/keith/lib/python3.11/site-packages/pyannote/audio/tasks/segmentation/mixins.py:37: UserWarning: `torchaudio.backend.common.AudioMetaData` has been moved to `torchaudio.AudioMetaData`. Please update the import path.\n",
      "  from torchaudio.backend.common import AudioMetaData\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "from fleurs import _FLEURS_LONG_TO_LANG\n",
    "from config import STORAGE_DIR_DATA_FLEURS \n",
    "from models import load_whisper_x\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages_long = \"English, Mandarin Chinese\".split(',')\n",
    "languages_lang = [_FLEURS_LONG_TO_LANG[long.strip()] for long in languages_long]\n",
    "\n",
    "dataset = load_dataset(\"google/fleurs\", name=languages_lang[1], cache_dir=STORAGE_DIR_DATA_FLEURS, trust_remote_code=True, split=\"test[:10%]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/keith/miniconda3/envs/keith/lib/python3.11/site-packages/datasets/load.py:756: FutureWarning: The repository for wer contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/wer/wer.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n",
      "/home/keith/miniconda3/envs/keith/lib/python3.11/site-packages/datasets/load.py:756: FutureWarning: The repository for cer contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/cer/cer.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4953516a8ab44328fb3175e37dc85be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/2.16k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wer_metric = load_metric(\"wer\")\n",
    "cer_metric = load_metric(\"cer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../.cache/torch/whisperx-vad-segmentation.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No language specified, language will be first be detected for each audio file (increases inference time).\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.1.1+cu121. Bad things might happen unless you revert torch to 1.x.\n"
     ]
    }
   ],
   "source": [
    "model = load_whisper_x(whisper_arch=\"medium\", device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: audio is shorter than 30s, language detection may be inaccurate.\n",
      "Detected language: zh (0.98) in first 30s of audio...\n",
      "这并不是告别这是一个篇章的结束也是新篇章的开始\n",
      "Warning: audio is shorter than 30s, language detection may be inaccurate.\n",
      "Detected language: zh (1.00) in first 30s of audio...\n",
      "盖甲等元素属于金属银和金等元素当然也是金属\n",
      "Warning: audio is shorter than 30s, language detection may be inaccurate.\n",
      "Detected language: zh (0.99) in first 30s of audio...\n",
      "橋下垂直淨空15米該項目於2011年8月完工但直到2017年3月才開始通車\n",
      "Warning: audio is shorter than 30s, language detection may be inaccurate.\n",
      "Detected language: zh (0.99) in first 30s of audio...\n",
      "适当使用博客可以使学生变得更善于分析和进行思辨,通过积极回忆网络材料,学生们可以在他人的文章的上下文语语境中找到自己的立场,并能够针对特定问题提出自己的观点。\n",
      "Warning: audio is shorter than 30s, language detection may be inaccurate.\n",
      "Detected language: zh (0.99) in first 30s of audio...\n",
      "科学家们可以得出结论暗物质对其他暗物质的影响方式与普通物质相同\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "batch = []\n",
    "results = []\n",
    "for idx in range(0, 5):\n",
    "    audio_array = dataset[idx][\"audio\"][\"array\"].astype(np.float32)\n",
    "    result = model.transcribe(audio_array, batch_size=batch_size)\n",
    "\n",
    "    transcription = result[\"segments\"][0]['text']\n",
    "    print(transcription)\n",
    "    results.append(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "references = dataset[0:5][\"transcription\"]\n",
    "predictions = []\n",
    "\n",
    "if dataset[0][\"language\"] == \"Mandarin Chinese\":\n",
    "    for idx, reference in enumerate(results):\n",
    "        # add spaces between characters\n",
    "        def detect_chinese(text):\n",
    "            has_chinese = any(\n",
    "                \"\\u4E00\" <= char <= \"\\u9FFF\" or \"\\u3400\" <= char <= \"\\u4DBF\"\n",
    "                for char in text\n",
    "            )\n",
    "            return has_chinese\n",
    "\n",
    "        reconstruct = \"\"\n",
    "        for idx, char in enumerate(reference):\n",
    "            if detect_chinese(char):\n",
    "                if idx != len(reference) - 1:\n",
    "                    reconstruct += char + \" \"\n",
    "                else:\n",
    "                    reconstruct += char\n",
    "            else:\n",
    "                reconstruct += char\n",
    "\n",
    "        predictions.append(reconstruct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'audio': {'array': array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
      "       5.72800636e-05, 6.50286674e-05, 9.16719437e-05]),\n",
      "           'path': 'test/10026684690566417990.wav',\n",
      "           'sampling_rate': 16000},\n",
      " 'gender': 0,\n",
      " 'id': 1906,\n",
      " 'lang_group_id': 6,\n",
      " 'lang_id': 13,\n",
      " 'language': 'Mandarin Chinese',\n",
      " 'num_samples': 166080,\n",
      " 'path': '/run/media/keith/a1cdd4e6-1c93-4b0a-8e04-b49b3dfb68d9/data/fleurs/downloads/extracted/6ac5a80ec9f5461d7471fc483e93eca5de8b6dd8de8ee1d2f25f3adc0961cdf9/10026684690566417990.wav',\n",
      " 'raw_transcription': '“这并不是告别。这是一个篇章的结束，也是新篇章的开始。”',\n",
      " 'transcription': '这 并 不 是 告 别 这 是 一 个 篇 章 的 结 束 也 是 新 篇 章 的 开 始'}\n",
      "0.15\n",
      "0.0891891891891892\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(dataset[0])\n",
    "\n",
    "wer_result = wer_metric.compute(references=references, predictions=predictions)             \n",
    "cer_result = cer_metric.compute(references=references, predictions=predictions)             \n",
    "print(wer_result)\n",
    "print(cer_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keith",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
